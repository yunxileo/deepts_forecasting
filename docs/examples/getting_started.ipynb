{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install deepts_forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\DeepTS_Forecasting\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from deepts_forecasting.utils.data import TimeSeriesDataSet\n",
    "from torch.utils.data import DataLoader\n",
    "from deepts_forecasting.models.seq2seq import Seq2SeqNetwork\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from deepts_forecasting.utils.data.encoders import TorchNormalizer\n",
    "from deepts_forecasting.datasets import AirPassengersDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>group</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02-01</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03-01</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04-01</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05-01</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  Passengers  year month group  time_idx\n",
       "0 1949-01-01       112.0  1949     1     0         0\n",
       "1 1949-02-01       118.0  1949     2     0         1\n",
       "2 1949-03-01       132.0  1949     3     0         2\n",
       "3 1949-04-01       129.0  1949     4     0         3\n",
       "4 1949-05-01       121.0  1949     5     0         4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = AirPassengersDataset().load()\n",
    "data['year'] = data['Month'].dt.year\n",
    "data['month'] = data['Month'].dt.month\n",
    "data['group'] = '0'\n",
    "data['time_idx'] = np.arange(len(data))\n",
    "data['Passengers'] = data['Passengers'].astype(float)\n",
    "data['month'] = data['month'].astype('str')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 14\n",
    "max_prediction_length = 12\n",
    "\n",
    "training_cutoff = data[\"time_idx\"].max() - max_encoder_length - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    max_encoder_length= max_encoder_length,\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Passengers\",\n",
    "    group_ids=[\"group\"],\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=['month'],\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_unknown_reals=[\"Passengers\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    target_normalizer=TorchNormalizer(method=\"standard\",\n",
    "                                      transformation=None),\n",
    "    )\n",
    "\n",
    "training.get_parameters()\n",
    "validation = TimeSeriesDataSet.from_dataset(training,\n",
    "                                            data[lambda x: x.time_idx > training_cutoff])\n",
    "\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(training, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "val_dataloader = DataLoader(validation, batch_size=batch_size, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method LightningModule.summarize of Seq2SeqNetwork(\n",
       "  (loss): L1Loss()\n",
       "  (logging_metrics): ModuleList()\n",
       "  (dense_layer): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (encode_rnn): LSTM(7, 50, num_layers=3, batch_first=True)\n",
       "  (decode_rnn): LSTM(6, 50, num_layers=3, batch_first=True)\n",
       "  (embeddings): ModuleDict(\n",
       "    (month): Embedding(12, 6)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(123)\n",
    "# create PyTorch Lighning Trainer with early stopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4,\n",
    "                                    patience=60, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    gpus=0,  # run on CPU, if on multiple GPUs, use accelerator=\"ddp\"\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # 30 batches per epoch\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=TensorBoardLogger(\"lightning_logs\")\n",
    ")\n",
    "\n",
    "model = Seq2SeqNetwork.from_dataset(training,\n",
    "                                    hidden_size=50,\n",
    "                                    rnn_layers=3)\n",
    "model.summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"categorical_groups\":                {}\n",
       "\"cell_type\":                         LSTM\n",
       "\"embedding_labels\":                  {'month': array(['1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       "      dtype=object)}\n",
       "\"embedding_paddings\":                []\n",
       "\"embedding_sizes\":                   {'month': [12, 6]}\n",
       "\"hidden_size\":                       50\n",
       "\"learning_rate\":                     0.001\n",
       "\"log_interval\":                      -1\n",
       "\"log_val_interval\":                  None\n",
       "\"logging_metrics\":                   ModuleList()\n",
       "\"loss\":                              L1Loss()\n",
       "\"max_encoder_length\":                14\n",
       "\"max_prediction_length\":             12\n",
       "\"monotone_constaints\":               {}\n",
       "\"output_size\":                       1\n",
       "\"output_transformer\":                TorchNormalizer()\n",
       "\"rnn_layers\":                        3\n",
       "\"static_categoricals\":               []\n",
       "\"static_reals\":                      []\n",
       "\"time_varying_categoricals_decoder\": ['month']\n",
       "\"time_varying_categoricals_encoder\": ['month']\n",
       "\"time_varying_reals_decoder\":        []\n",
       "\"time_varying_reals_encoder\":        ['Passengers']\n",
       "\"x_categoricals\":                    ['month']\n",
       "\"x_reals\":                           ['Passengers']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\DeepTS_Forecasting\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:735: LightningDeprecationWarning: `trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.fit(train_dataloaders)` instead. HINT: added 's'\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | L1Loss     | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | dense_layer     | Linear     | 51    \n",
      "3 | encode_rnn      | LSTM       | 52.6 K\n",
      "4 | decode_rnn      | LSTM       | 52.4 K\n",
      "5 | embeddings      | ModuleDict | 72    \n",
      "-----------------------------------------------\n",
      "105 K     Trainable params\n",
      "0         Non-trainable params\n",
      "105 K     Total params\n",
      "0.420     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\DeepTS_Forecasting\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 123\n",
      "D:\\Anaconda3\\envs\\DeepTS_Forecasting\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "D:\\Anaconda3\\envs\\DeepTS_Forecasting\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  86%|█████████▍ | 6/7 [00:00<00:00, 26.90it/s, loss=0.742, v_num=13]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 7/7 [00:00<00:00, 29.66it/s, loss=0.742, v_num=13, val_loss=\u001b[A\n",
      "Epoch 1:  86%|▊| 6/7 [00:00<00:00, 20.00it/s, loss=0.734, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 7/7 [00:00<00:00, 22.08it/s, loss=0.734, v_num=13, val_loss=\u001b[A\n",
      "Epoch 2:  86%|▊| 6/7 [00:00<00:00, 11.89it/s, loss=0.731, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 7/7 [00:00<00:00, 13.22it/s, loss=0.731, v_num=13, val_loss=\u001b[A\n",
      "Epoch 3:  86%|▊| 6/7 [00:00<00:00, 13.23it/s, loss=0.77, v_num=13, val_loss=2\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 7/7 [00:00<00:00, 14.69it/s, loss=0.77, v_num=13, val_loss=2\u001b[A\n",
      "Epoch 4:  86%|▊| 6/7 [00:00<00:00, 12.19it/s, loss=0.768, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 7/7 [00:00<00:00, 13.64it/s, loss=0.768, v_num=13, val_loss=\u001b[A\n",
      "Epoch 5:  86%|▊| 6/7 [00:00<00:00, 13.59it/s, loss=0.765, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 7/7 [00:00<00:00, 15.05it/s, loss=0.765, v_num=13, val_loss=\u001b[A\n",
      "Epoch 6:  86%|▊| 6/7 [00:00<00:00, 13.51it/s, loss=0.76, v_num=13, val_loss=2\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 7/7 [00:00<00:00, 14.95it/s, loss=0.76, v_num=13, val_loss=2\u001b[A\n",
      "Epoch 7:  86%|▊| 6/7 [00:00<00:00, 14.10it/s, loss=0.746, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 7/7 [00:00<00:00, 15.55it/s, loss=0.746, v_num=13, val_loss=\u001b[A\n",
      "Epoch 8:  86%|▊| 6/7 [00:00<00:00, 14.61it/s, loss=0.711, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 7/7 [00:00<00:00, 16.13it/s, loss=0.711, v_num=13, val_loss=\u001b[A\n",
      "Epoch 9:  86%|▊| 6/7 [00:00<00:00, 13.04it/s, loss=0.646, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 7/7 [00:00<00:00, 14.33it/s, loss=0.646, v_num=13, val_loss=\u001b[A\n",
      "Epoch 10:  86%|▊| 6/7 [00:00<00:00, 13.73it/s, loss=0.564, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 7/7 [00:00<00:00, 15.25it/s, loss=0.564, v_num=13, val_loss\u001b[A\n",
      "Epoch 11:  86%|▊| 6/7 [00:00<00:00, 14.87it/s, loss=0.493, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 7/7 [00:00<00:00, 16.74it/s, loss=0.493, v_num=13, val_loss\u001b[A\n",
      "Epoch 12:  86%|▊| 6/7 [00:00<00:00, 16.59it/s, loss=0.433, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 7/7 [00:00<00:00, 18.49it/s, loss=0.433, v_num=13, val_loss\u001b[A\n",
      "Epoch 13:  86%|▊| 6/7 [00:00<00:00, 16.46it/s, loss=0.378, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 7/7 [00:00<00:00, 18.42it/s, loss=0.378, v_num=13, val_loss\u001b[A\n",
      "Epoch 14:  86%|▊| 6/7 [00:00<00:00, 20.61it/s, loss=0.32, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 7/7 [00:00<00:00, 22.87it/s, loss=0.32, v_num=13, val_loss=\u001b[A\n",
      "Epoch 15:  86%|▊| 6/7 [00:00<00:00, 18.18it/s, loss=0.3, v_num=13, val_loss=1\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 7/7 [00:00<00:00, 20.23it/s, loss=0.3, v_num=13, val_loss=0\u001b[A\n",
      "Epoch 16:  86%|▊| 6/7 [00:00<00:00, 17.62it/s, loss=0.289, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 7/7 [00:00<00:00, 19.31it/s, loss=0.289, v_num=13, val_loss\u001b[A\n",
      "Epoch 17:  86%|▊| 6/7 [00:00<00:00, 19.90it/s, loss=0.277, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 7/7 [00:00<00:00, 22.04it/s, loss=0.277, v_num=13, val_loss\u001b[A\n",
      "Epoch 18:  86%|▊| 6/7 [00:00<00:00, 17.12it/s, loss=0.258, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 7/7 [00:00<00:00, 19.04it/s, loss=0.258, v_num=13, val_loss\u001b[A\n",
      "Epoch 19:  86%|▊| 6/7 [00:00<00:00, 19.41it/s, loss=0.245, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 7/7 [00:00<00:00, 21.60it/s, loss=0.245, v_num=13, val_loss\u001b[A\n",
      "Epoch 20:  86%|▊| 6/7 [00:00<00:00, 20.47it/s, loss=0.239, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 7/7 [00:00<00:00, 22.76it/s, loss=0.239, v_num=13, val_loss\u001b[A\n",
      "Epoch 21:  86%|▊| 6/7 [00:00<00:00, 20.69it/s, loss=0.228, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 7/7 [00:00<00:00, 22.87it/s, loss=0.228, v_num=13, val_loss\u001b[A\n",
      "Epoch 22:  86%|▊| 6/7 [00:00<00:00, 20.20it/s, loss=0.246, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 7/7 [00:00<00:00, 22.40it/s, loss=0.246, v_num=13, val_loss\u001b[A\n",
      "Epoch 23:  86%|▊| 6/7 [00:00<00:00, 20.65it/s, loss=0.238, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 7/7 [00:00<00:00, 22.61it/s, loss=0.238, v_num=13, val_loss\u001b[A\n",
      "Epoch 24:  86%|▊| 6/7 [00:00<00:00, 17.67it/s, loss=0.239, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 7/7 [00:00<00:00, 19.69it/s, loss=0.239, v_num=13, val_loss\u001b[A\n",
      "Epoch 25:  86%|▊| 6/7 [00:00<00:00, 19.60it/s, loss=0.225, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 7/7 [00:00<00:00, 21.47it/s, loss=0.225, v_num=13, val_loss\u001b[A\n",
      "Epoch 26:  86%|▊| 6/7 [00:00<00:00, 17.36it/s, loss=0.22, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 7/7 [00:00<00:00, 18.94it/s, loss=0.22, v_num=13, val_loss=\u001b[A\n",
      "Epoch 27:  86%|▊| 6/7 [00:00<00:00, 17.26it/s, loss=0.216, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 7/7 [00:00<00:00, 19.04it/s, loss=0.216, v_num=13, val_loss\u001b[A\n",
      "Epoch 28:  86%|▊| 6/7 [00:00<00:00, 17.49it/s, loss=0.218, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 7/7 [00:00<00:00, 19.55it/s, loss=0.218, v_num=13, val_loss\u001b[A\n",
      "Epoch 29:  86%|▊| 6/7 [00:00<00:00, 17.91it/s, loss=0.221, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 7/7 [00:00<00:00, 19.77it/s, loss=0.221, v_num=13, val_loss\u001b[A\n",
      "Epoch 30:  86%|▊| 6/7 [00:00<00:00, 20.69it/s, loss=0.209, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 7/7 [00:00<00:00, 23.06it/s, loss=0.209, v_num=13, val_loss\u001b[A\n",
      "Epoch 31:  86%|▊| 6/7 [00:00<00:00, 20.30it/s, loss=0.208, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 7/7 [00:00<00:00, 22.58it/s, loss=0.208, v_num=13, val_loss\u001b[A\n",
      "Epoch 32:  86%|▊| 6/7 [00:00<00:00, 20.44it/s, loss=0.195, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 7/7 [00:00<00:00, 22.69it/s, loss=0.195, v_num=13, val_loss\u001b[A\n",
      "Epoch 33:  86%|▊| 6/7 [00:00<00:00, 19.83it/s, loss=0.191, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 7/7 [00:00<00:00, 22.01it/s, loss=0.191, v_num=13, val_loss\u001b[A\n",
      "Epoch 34:  86%|▊| 6/7 [00:00<00:00, 20.90it/s, loss=0.187, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 7/7 [00:00<00:00, 23.10it/s, loss=0.187, v_num=13, val_loss\u001b[A\n",
      "Epoch 35:  86%|▊| 6/7 [00:00<00:00, 19.41it/s, loss=0.175, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 7/7 [00:00<00:00, 21.63it/s, loss=0.175, v_num=13, val_loss\u001b[A\n",
      "Epoch 36:  86%|▊| 6/7 [00:00<00:00, 21.05it/s, loss=0.16, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 7/7 [00:00<00:00, 23.37it/s, loss=0.16, v_num=13, val_loss=\u001b[A\n",
      "Epoch 37:  86%|▊| 6/7 [00:00<00:00, 18.72it/s, loss=0.146, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 7/7 [00:00<00:00, 20.83it/s, loss=0.146, v_num=13, val_loss\u001b[A\n",
      "Epoch 38:  86%|▊| 6/7 [00:00<00:00, 18.84it/s, loss=0.14, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 7/7 [00:00<00:00, 20.92it/s, loss=0.14, v_num=13, val_loss=\u001b[A\n",
      "Epoch 39:  86%|▊| 6/7 [00:00<00:00, 19.67it/s, loss=0.151, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 7/7 [00:00<00:00, 21.74it/s, loss=0.151, v_num=13, val_loss\u001b[A\n",
      "Epoch 40:  86%|▊| 6/7 [00:00<00:00, 18.89it/s, loss=0.151, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40: 100%|█| 7/7 [00:00<00:00, 21.05it/s, loss=0.151, v_num=13, val_loss\u001b[A\n",
      "Epoch 41:  86%|▊| 6/7 [00:00<00:00, 17.91it/s, loss=0.147, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41: 100%|█| 7/7 [00:00<00:00, 19.91it/s, loss=0.147, v_num=13, val_loss\u001b[A\n",
      "Epoch 42:  86%|▊| 6/7 [00:00<00:00, 20.13it/s, loss=0.159, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42: 100%|█| 7/7 [00:00<00:00, 22.32it/s, loss=0.159, v_num=13, val_loss\u001b[A\n",
      "Epoch 43:  86%|▊| 6/7 [00:00<00:00, 16.99it/s, loss=0.145, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43: 100%|█| 7/7 [00:00<00:00, 18.54it/s, loss=0.145, v_num=13, val_loss\u001b[A\n",
      "Epoch 44:  86%|▊| 6/7 [00:00<00:00, 18.15it/s, loss=0.147, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44: 100%|█| 7/7 [00:00<00:00, 20.23it/s, loss=0.147, v_num=13, val_loss\u001b[A\n",
      "Epoch 45:  86%|▊| 6/7 [00:00<00:00, 19.32it/s, loss=0.142, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45: 100%|█| 7/7 [00:00<00:00, 21.31it/s, loss=0.142, v_num=13, val_loss\u001b[A\n",
      "Epoch 46:  86%|▊| 6/7 [00:00<00:00, 19.32it/s, loss=0.137, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 46: 100%|█| 7/7 [00:00<00:00, 21.37it/s, loss=0.137, v_num=13, val_loss\u001b[A\n",
      "Epoch 47:  86%|▊| 6/7 [00:00<00:00, 19.57it/s, loss=0.159, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47: 100%|█| 7/7 [00:00<00:00, 21.84it/s, loss=0.159, v_num=13, val_loss\u001b[A\n",
      "Epoch 48:  86%|▊| 6/7 [00:00<00:00, 20.27it/s, loss=0.159, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48: 100%|█| 7/7 [00:00<00:00, 22.58it/s, loss=0.159, v_num=13, val_loss\u001b[A\n",
      "Epoch 49:  86%|▊| 6/7 [00:00<00:00, 18.37it/s, loss=0.155, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49: 100%|█| 7/7 [00:00<00:00, 20.40it/s, loss=0.155, v_num=13, val_loss\u001b[A\n",
      "Epoch 50:  86%|▊| 6/7 [00:00<00:00, 17.46it/s, loss=0.147, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50: 100%|█| 7/7 [00:00<00:00, 19.39it/s, loss=0.147, v_num=13, val_loss\u001b[A\n",
      "Epoch 51:  86%|▊| 6/7 [00:00<00:00, 19.70it/s, loss=0.137, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51: 100%|█| 7/7 [00:00<00:00, 21.94it/s, loss=0.137, v_num=13, val_loss\u001b[A\n",
      "Epoch 52:  86%|▊| 6/7 [00:00<00:00, 18.43it/s, loss=0.139, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52: 100%|█| 7/7 [00:00<00:00, 20.43it/s, loss=0.139, v_num=13, val_loss\u001b[A\n",
      "Epoch 53:  86%|▊| 6/7 [00:00<00:00, 17.77it/s, loss=0.146, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53: 100%|█| 7/7 [00:00<00:00, 19.88it/s, loss=0.146, v_num=13, val_loss\u001b[A\n",
      "Epoch 54:  86%|▊| 6/7 [00:00<00:00, 20.79it/s, loss=0.145, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54: 100%|█| 7/7 [00:00<00:00, 22.87it/s, loss=0.145, v_num=13, val_loss\u001b[A\n",
      "Epoch 55:  86%|▊| 6/7 [00:00<00:00, 16.48it/s, loss=0.15, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55: 100%|█| 7/7 [00:00<00:00, 18.04it/s, loss=0.15, v_num=13, val_loss=\u001b[A\n",
      "Epoch 56:  86%|▊| 6/7 [00:00<00:00, 17.34it/s, loss=0.144, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56: 100%|█| 7/7 [00:00<00:00, 19.41it/s, loss=0.144, v_num=13, val_loss\u001b[A\n",
      "Epoch 57:  86%|▊| 6/7 [00:00<00:00, 14.85it/s, loss=0.138, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 57: 100%|█| 7/7 [00:00<00:00, 16.60it/s, loss=0.138, v_num=13, val_loss\u001b[A\n",
      "Epoch 58:  86%|▊| 6/7 [00:00<00:00, 15.40it/s, loss=0.137, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58: 100%|█| 7/7 [00:00<00:00, 17.11it/s, loss=0.137, v_num=13, val_loss\u001b[A\n",
      "Epoch 59:  86%|▊| 6/7 [00:00<00:00, 15.87it/s, loss=0.123, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 59: 100%|█| 7/7 [00:00<00:00, 17.50it/s, loss=0.123, v_num=13, val_loss\u001b[A\n",
      "Epoch 60:  86%|▊| 6/7 [00:00<00:00, 19.26it/s, loss=0.116, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60: 100%|█| 7/7 [00:00<00:00, 21.44it/s, loss=0.116, v_num=13, val_loss\u001b[A\n",
      "Epoch 61:  86%|▊| 6/7 [00:00<00:00, 19.48it/s, loss=0.131, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61: 100%|█| 7/7 [00:00<00:00, 21.67it/s, loss=0.131, v_num=13, val_loss\u001b[A\n",
      "Epoch 62:  86%|▊| 6/7 [00:00<00:00, 20.13it/s, loss=0.139, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62: 100%|█| 7/7 [00:00<00:00, 22.29it/s, loss=0.139, v_num=13, val_loss\u001b[A\n",
      "Epoch 63:  86%|▊| 6/7 [00:00<00:00, 21.27it/s, loss=0.137, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63: 100%|█| 7/7 [00:00<00:00, 23.64it/s, loss=0.137, v_num=13, val_loss\u001b[A\n",
      "Epoch 64:  86%|▊| 6/7 [00:00<00:00, 20.54it/s, loss=0.126, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 64: 100%|█| 7/7 [00:00<00:00, 22.83it/s, loss=0.126, v_num=13, val_loss\u001b[A\n",
      "Epoch 65:  86%|▊| 6/7 [00:00<00:00, 20.23it/s, loss=0.114, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65: 100%|█| 7/7 [00:00<00:00, 22.43it/s, loss=0.114, v_num=13, val_loss\u001b[A\n",
      "Epoch 66:  86%|▊| 6/7 [00:00<00:00, 20.34it/s, loss=0.11, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66: 100%|█| 7/7 [00:00<00:00, 22.58it/s, loss=0.11, v_num=13, val_loss=\u001b[A\n",
      "Epoch 67:  86%|▊| 6/7 [00:00<00:00, 20.98it/s, loss=0.111, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67: 100%|█| 7/7 [00:00<00:00, 23.37it/s, loss=0.111, v_num=13, val_loss\u001b[A\n",
      "Epoch 68:  86%|▊| 6/7 [00:00<00:00, 18.83it/s, loss=0.118, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68: 100%|█| 7/7 [00:00<00:00, 21.05it/s, loss=0.118, v_num=13, val_loss\u001b[A\n",
      "Epoch 69:  86%|▊| 6/7 [00:00<00:00, 20.06it/s, loss=0.12, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 69: 100%|█| 7/7 [00:00<00:00, 22.29it/s, loss=0.12, v_num=13, val_loss=\u001b[A\n",
      "Epoch 70:  86%|▊| 6/7 [00:00<00:00, 20.69it/s, loss=0.116, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 70: 100%|█| 7/7 [00:00<00:00, 23.02it/s, loss=0.116, v_num=13, val_loss\u001b[A\n",
      "Epoch 71:  86%|▊| 6/7 [00:00<00:00, 19.20it/s, loss=0.11, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 71: 100%|█| 7/7 [00:00<00:00, 21.37it/s, loss=0.11, v_num=13, val_loss=\u001b[A\n",
      "Epoch 72:  86%|▊| 6/7 [00:00<00:00, 19.48it/s, loss=0.107, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 72: 100%|█| 7/7 [00:00<00:00, 21.84it/s, loss=0.107, v_num=13, val_loss\u001b[A\n",
      "Epoch 73:  86%|▊| 6/7 [00:00<00:00, 21.12it/s, loss=0.122, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 73: 100%|█| 7/7 [00:00<00:00, 23.37it/s, loss=0.122, v_num=13, val_loss\u001b[A\n",
      "Epoch 74:  86%|▊| 6/7 [00:00<00:00, 21.01it/s, loss=0.12, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 74: 100%|█| 7/7 [00:00<00:00, 23.29it/s, loss=0.12, v_num=13, val_loss=\u001b[A\n",
      "Epoch 75:  86%|▊| 6/7 [00:00<00:00, 19.70it/s, loss=0.146, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 75: 100%|█| 7/7 [00:00<00:00, 21.97it/s, loss=0.146, v_num=13, val_loss\u001b[A\n",
      "Epoch 76:  86%|▊| 6/7 [00:00<00:00, 20.47it/s, loss=0.143, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 76: 100%|█| 7/7 [00:00<00:00, 22.76it/s, loss=0.143, v_num=13, val_loss\u001b[A\n",
      "Epoch 77:  86%|▊| 6/7 [00:00<00:00, 20.40it/s, loss=0.129, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 77: 100%|█| 7/7 [00:00<00:00, 22.65it/s, loss=0.129, v_num=13, val_loss\u001b[A\n",
      "Epoch 78:  86%|▊| 6/7 [00:00<00:00, 20.58it/s, loss=0.135, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 78: 100%|█| 7/7 [00:00<00:00, 22.87it/s, loss=0.135, v_num=13, val_loss\u001b[A\n",
      "Epoch 79:  86%|▊| 6/7 [00:00<00:00, 20.94it/s, loss=0.12, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 79: 100%|█| 7/7 [00:00<00:00, 23.21it/s, loss=0.12, v_num=13, val_loss=\u001b[A\n",
      "Epoch 80:  86%|▊| 6/7 [00:00<00:00, 20.27it/s, loss=0.119, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 80: 100%|█| 7/7 [00:00<00:00, 22.58it/s, loss=0.119, v_num=13, val_loss\u001b[A\n",
      "Epoch 81:  86%|▊| 6/7 [00:00<00:00, 19.90it/s, loss=0.124, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81: 100%|█| 7/7 [00:00<00:00, 22.04it/s, loss=0.124, v_num=13, val_loss\u001b[A\n",
      "Epoch 82:  86%|▊| 6/7 [00:00<00:00, 17.77it/s, loss=0.114, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 82: 100%|█| 7/7 [00:00<00:00, 19.41it/s, loss=0.114, v_num=13, val_loss\u001b[A\n",
      "Epoch 83:  86%|▊| 6/7 [00:00<00:00, 13.27it/s, loss=0.111, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83: 100%|█| 7/7 [00:00<00:00, 14.83it/s, loss=0.111, v_num=13, val_loss\u001b[A\n",
      "Epoch 84:  86%|▊| 6/7 [00:00<00:00, 22.01it/s, loss=0.113, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 84: 100%|█| 7/7 [00:00<00:00, 24.43it/s, loss=0.113, v_num=13, val_loss\u001b[A\n",
      "Epoch 85:  86%|▊| 6/7 [00:00<00:00, 17.99it/s, loss=0.11, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 85: 100%|█| 7/7 [00:00<00:00, 19.66it/s, loss=0.11, v_num=13, val_loss=\u001b[A\n",
      "Epoch 86:  86%|▊| 6/7 [00:00<00:00, 15.81it/s, loss=0.115, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 86: 100%|█| 7/7 [00:00<00:00, 17.58it/s, loss=0.115, v_num=13, val_loss\u001b[A\n",
      "Epoch 87:  86%|▊| 6/7 [00:00<00:00, 16.62it/s, loss=0.118, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 87: 100%|█| 7/7 [00:00<00:00, 18.30it/s, loss=0.118, v_num=13, val_loss\u001b[A\n",
      "Epoch 88:  86%|▊| 6/7 [00:00<00:00, 15.28it/s, loss=0.115, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 88: 100%|█| 7/7 [00:00<00:00, 17.22it/s, loss=0.115, v_num=13, val_loss\u001b[A\n",
      "Epoch 89:  86%|▊| 6/7 [00:00<00:00, 20.83it/s, loss=0.12, v_num=13, val_loss=\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89: 100%|█| 7/7 [00:00<00:00, 23.17it/s, loss=0.12, v_num=13, val_loss=\u001b[A\n",
      "Epoch 90:  86%|▊| 6/7 [00:00<00:00, 21.09it/s, loss=0.117, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90: 100%|█| 7/7 [00:00<00:00, 23.41it/s, loss=0.117, v_num=13, val_loss\u001b[A\n",
      "Epoch 91:  86%|▊| 6/7 [00:00<00:00, 17.57it/s, loss=0.117, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 91: 100%|█| 7/7 [00:00<00:00, 19.69it/s, loss=0.117, v_num=13, val_loss\u001b[A\n",
      "Epoch 92:  86%|▊| 6/7 [00:00<00:00, 19.10it/s, loss=0.119, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 92: 100%|█| 7/7 [00:00<00:00, 21.27it/s, loss=0.119, v_num=13, val_loss\u001b[A\n",
      "Epoch 93:  86%|▊| 6/7 [00:00<00:00, 17.91it/s, loss=0.114, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 93: 100%|█| 7/7 [00:00<00:00, 20.08it/s, loss=0.114, v_num=13, val_loss\u001b[A\n",
      "Epoch 94:  86%|▊| 6/7 [00:00<00:00, 18.40it/s, loss=0.111, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94: 100%|█| 7/7 [00:00<00:00, 20.44it/s, loss=0.111, v_num=13, val_loss\u001b[A\n",
      "Epoch 95:  86%|▊| 6/7 [00:00<00:00, 21.24it/s, loss=0.116, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95: 100%|█| 7/7 [00:00<00:00, 23.64it/s, loss=0.116, v_num=13, val_loss\u001b[A\n",
      "Epoch 96:  86%|▊| 6/7 [00:00<00:00, 20.72it/s, loss=0.124, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96: 100%|█| 7/7 [00:00<00:00, 22.98it/s, loss=0.124, v_num=13, val_loss\u001b[A\n",
      "Epoch 97:  86%|▊| 6/7 [00:00<00:00, 21.46it/s, loss=0.123, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 97: 100%|█| 7/7 [00:00<00:00, 23.85it/s, loss=0.123, v_num=13, val_loss\u001b[A\n",
      "Epoch 98:  86%|▊| 6/7 [00:00<00:00, 20.83it/s, loss=0.116, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98: 100%|█| 7/7 [00:00<00:00, 23.06it/s, loss=0.116, v_num=13, val_loss\u001b[A\n",
      "Epoch 99:  86%|▊| 6/7 [00:00<00:00, 18.23it/s, loss=0.108, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 99: 100%|█| 7/7 [00:00<00:00, 19.31it/s, loss=0.108, v_num=13, val_loss\u001b[A\n",
      "Epoch 100:  86%|▊| 6/7 [00:00<00:00, 16.64it/s, loss=0.107, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 100: 100%|█| 7/7 [00:00<00:00, 18.47it/s, loss=0.107, v_num=13, val_los\u001b[A\n",
      "Epoch 101:  86%|▊| 6/7 [00:00<00:00, 20.47it/s, loss=0.114, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 101: 100%|█| 7/7 [00:00<00:00, 22.80it/s, loss=0.114, v_num=13, val_los\u001b[A\n",
      "Epoch 102:  86%|▊| 6/7 [00:00<00:00, 19.90it/s, loss=0.126, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 102: 100%|█| 7/7 [00:00<00:00, 21.87it/s, loss=0.126, v_num=13, val_los\u001b[A\n",
      "Epoch 103:  86%|▊| 6/7 [00:00<00:00, 19.23it/s, loss=0.115, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 103: 100%|█| 7/7 [00:00<00:00, 21.14it/s, loss=0.115, v_num=13, val_los\u001b[A\n",
      "Epoch 104:  86%|▊| 6/7 [00:00<00:00, 18.95it/s, loss=0.117, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 104: 100%|█| 7/7 [00:00<00:00, 21.02it/s, loss=0.117, v_num=13, val_los\u001b[A\n",
      "Epoch 105:  86%|▊| 6/7 [00:00<00:00, 19.93it/s, loss=0.104, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 105: 100%|█| 7/7 [00:00<00:00, 22.25it/s, loss=0.104, v_num=13, val_los\u001b[A\n",
      "Epoch 106:  86%|▊| 6/7 [00:00<00:00, 21.12it/s, loss=0.105, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 106: 100%|█| 7/7 [00:00<00:00, 23.45it/s, loss=0.105, v_num=13, val_los\u001b[A\n",
      "Epoch 107:  86%|▊| 6/7 [00:00<00:00, 17.31it/s, loss=0.113, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 107: 100%|█| 7/7 [00:00<00:00, 19.23it/s, loss=0.113, v_num=13, val_los\u001b[A\n",
      "Epoch 108:  86%|▊| 6/7 [00:00<00:00, 20.16it/s, loss=0.111, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 108: 100%|█| 7/7 [00:00<00:00, 22.50it/s, loss=0.111, v_num=13, val_los\u001b[A\n",
      "Epoch 109:  86%|▊| 6/7 [00:00<00:00, 20.83it/s, loss=0.109, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 109: 100%|█| 7/7 [00:00<00:00, 23.25it/s, loss=0.109, v_num=13, val_los\u001b[A\n",
      "Epoch 110:  86%|▊| 6/7 [00:00<00:00, 21.35it/s, loss=0.121, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 110: 100%|█| 7/7 [00:00<00:00, 23.64it/s, loss=0.121, v_num=13, val_los\u001b[A\n",
      "Epoch 111:  86%|▊| 6/7 [00:00<00:00, 21.16it/s, loss=0.112, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 111: 100%|█| 7/7 [00:00<00:00, 23.53it/s, loss=0.112, v_num=13, val_los\u001b[A\n",
      "Epoch 112:  86%|▊| 6/7 [00:00<00:00, 18.49it/s, loss=0.128, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 112: 100%|█| 7/7 [00:00<00:00, 20.43it/s, loss=0.128, v_num=13, val_los\u001b[A\n",
      "Epoch 113:  86%|▊| 6/7 [00:00<00:00, 17.54it/s, loss=0.121, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 113: 100%|█| 7/7 [00:00<00:00, 19.36it/s, loss=0.121, v_num=13, val_los\u001b[A\n",
      "Epoch 114:  86%|▊| 6/7 [00:00<00:00, 18.26it/s, loss=0.113, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 114: 100%|█| 7/7 [00:00<00:00, 20.40it/s, loss=0.113, v_num=13, val_los\u001b[A\n",
      "Epoch 115:  86%|▊| 6/7 [00:00<00:00, 17.12it/s, loss=0.121, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 115: 100%|█| 7/7 [00:00<00:00, 19.12it/s, loss=0.121, v_num=13, val_los\u001b[A\n",
      "Epoch 116:  86%|▊| 6/7 [00:00<00:00, 16.78it/s, loss=0.107, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 116: 100%|█| 7/7 [00:00<00:00, 18.59it/s, loss=0.107, v_num=13, val_los\u001b[A\n",
      "Epoch 117:  86%|▊| 6/7 [00:00<00:00, 17.85it/s, loss=0.111, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 117: 100%|█| 7/7 [00:00<00:00, 19.83it/s, loss=0.111, v_num=13, val_los\u001b[A\n",
      "Epoch 118:  86%|▊| 6/7 [00:00<00:00, 16.21it/s, loss=0.11, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 118: 100%|█| 7/7 [00:00<00:00, 17.97it/s, loss=0.11, v_num=13, val_loss\u001b[A\n",
      "Epoch 119:  86%|▊| 6/7 [00:00<00:00, 19.07it/s, loss=0.109, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 119: 100%|█| 7/7 [00:00<00:00, 21.02it/s, loss=0.109, v_num=13, val_los\u001b[A\n",
      "Epoch 120:  86%|▊| 6/7 [00:00<00:00, 18.46it/s, loss=0.112, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 120: 100%|█| 7/7 [00:00<00:00, 20.46it/s, loss=0.112, v_num=13, val_los\u001b[A\n",
      "Epoch 121:  86%|▊| 6/7 [00:00<00:00, 18.92it/s, loss=0.108, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 121: 100%|█| 7/7 [00:00<00:00, 21.05it/s, loss=0.108, v_num=13, val_los\u001b[A\n",
      "Epoch 122:  86%|▊| 6/7 [00:00<00:00, 18.54it/s, loss=0.103, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 122: 100%|█| 7/7 [00:00<00:00, 20.74it/s, loss=0.103, v_num=13, val_los\u001b[A\n",
      "Epoch 123:  86%|▊| 6/7 [00:00<00:00, 23.57it/s, loss=0.11, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 123: 100%|█| 7/7 [00:00<00:00, 26.02it/s, loss=0.11, v_num=13, val_loss\u001b[A\n",
      "Epoch 124:  86%|▊| 6/7 [00:00<00:00, 21.70it/s, loss=0.104, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 124: 100%|█| 7/7 [00:00<00:00, 24.05it/s, loss=0.104, v_num=13, val_los\u001b[A\n",
      "Epoch 125:  86%|▊| 6/7 [00:00<00:00, 20.06it/s, loss=0.132, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 125: 100%|█| 7/7 [00:00<00:00, 22.43it/s, loss=0.132, v_num=13, val_los\u001b[A\n",
      "Epoch 126:  86%|▊| 6/7 [00:00<00:00, 23.25it/s, loss=0.132, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 126: 100%|█| 7/7 [00:00<00:00, 25.68it/s, loss=0.132, v_num=13, val_los\u001b[A\n",
      "Epoch 127:  86%|▊| 6/7 [00:00<00:00, 22.90it/s, loss=0.127, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 127: 100%|█| 7/7 [00:00<00:00, 25.50it/s, loss=0.127, v_num=13, val_los\u001b[A\n",
      "Epoch 128:  86%|▊| 6/7 [00:00<00:00, 20.06it/s, loss=0.129, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 128: 100%|█| 7/7 [00:00<00:00, 22.40it/s, loss=0.129, v_num=13, val_los\u001b[A\n",
      "Epoch 129:  86%|▊| 6/7 [00:00<00:00, 23.21it/s, loss=0.102, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 129: 100%|█| 7/7 [00:00<00:00, 25.50it/s, loss=0.102, v_num=13, val_los\u001b[A\n",
      "Epoch 130:  86%|▊| 6/7 [00:00<00:00, 23.34it/s, loss=0.11, v_num=13, val_loss\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 130: 100%|█| 7/7 [00:00<00:00, 25.83it/s, loss=0.11, v_num=13, val_loss\u001b[A\n",
      "Epoch 131:  86%|▊| 6/7 [00:00<00:00, 22.94it/s, loss=0.106, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 131: 100%|█| 7/7 [00:00<00:00, 25.36it/s, loss=0.106, v_num=13, val_los\u001b[A\n",
      "Epoch 132:  86%|▊| 6/7 [00:00<00:00, 23.48it/s, loss=0.107, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 132: 100%|█| 7/7 [00:00<00:00, 25.97it/s, loss=0.107, v_num=13, val_los\u001b[A\n",
      "Epoch 133:  86%|▊| 6/7 [00:00<00:00, 23.85it/s, loss=0.0988, v_num=13, val_lo\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 133: 100%|█| 7/7 [00:00<00:00, 26.41it/s, loss=0.0988, v_num=13, val_lo\u001b[A\n",
      "Epoch 134:  86%|▊| 6/7 [00:00<00:00, 23.81it/s, loss=0.0987, v_num=13, val_lo\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 134: 100%|█| 7/7 [00:00<00:00, 26.41it/s, loss=0.0987, v_num=13, val_lo\u001b[A\n",
      "Epoch 135:  86%|▊| 6/7 [00:00<00:00, 22.94it/s, loss=0.109, v_num=13, val_los\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 135: 100%|█| 7/7 [00:00<00:00, 25.27it/s, loss=0.109, v_num=13, val_los\u001b[A\n",
      "Epoch 135: 100%|█| 7/7 [00:00<00:00, 23.41it/s, loss=0.109, v_num=13, val_los\u001b[A\n",
      "tensor([[[417.0000],\n",
      "         [391.0000],\n",
      "         [419.0000],\n",
      "         [461.0000],\n",
      "         [472.0000],\n",
      "         [535.0000],\n",
      "         [622.0000],\n",
      "         [606.0000],\n",
      "         [508.0000],\n",
      "         [461.0000],\n",
      "         [390.0000],\n",
      "         [432.0000]],\n",
      "\n",
      "        [[357.2356],\n",
      "         [359.2705],\n",
      "         [406.4317],\n",
      "         [408.9790],\n",
      "         [412.3742],\n",
      "         [482.3345],\n",
      "         [520.9820],\n",
      "         [521.2548],\n",
      "         [458.2994],\n",
      "         [391.1345],\n",
      "         [353.4926],\n",
      "         [381.9161]]], dtype=torch.float64)\n",
      "MAE is: tensor(55.0246, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader,\n",
    ")\n",
    "\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = Seq2SeqNetwork.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([model.transform_output(prediction=y, target_scale=x['target_scale'])\n",
    "                     for x, y in iter(val_dataloader)])\n",
    "predictions, x_index = best_model.predict(val_dataloader)\n",
    "mae = (actuals - predictions).abs().mean()\n",
    "# print('predictions shape is:', predictions.shape)\n",
    "# print('actuals shape is:', actuals.shape)\n",
    "print(torch.cat([actuals, predictions]))\n",
    "print('MAE is:', mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
