{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install deepts_forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\DeepTS_Forecasting\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from deepts_forecasting.utils.data import TimeSeriesDataSet\n",
    "from deepts_forecasting.utils.data.encoders import TorchNormalizer\n",
    "from deepts_forecasting.datasets import AirPassengersDataset\n",
    "from deepts_forecasting.models.tcn.tcn import TCNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>group</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02-01</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03-01</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04-01</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05-01</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  Passengers  year month group  time_idx\n",
       "0 1949-01-01       112.0  1949     1     0         0\n",
       "1 1949-02-01       118.0  1949     2     0         1\n",
       "2 1949-03-01       132.0  1949     3     0         2\n",
       "3 1949-04-01       129.0  1949     4     0         3\n",
       "4 1949-05-01       121.0  1949     5     0         4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = AirPassengersDataset().load()\n",
    "data['year'] = data['Month'].dt.year\n",
    "data['month'] = data['Month'].dt.month\n",
    "data['group'] = '0'\n",
    "data['time_idx'] = np.arange(len(data))\n",
    "data['Passengers'] = data['Passengers'].astype(float)\n",
    "data['month'] = data['month'].astype('str')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 18\n",
    "max_prediction_length = 12\n",
    "\n",
    "training_cutoff = data[\"time_idx\"].max() - max_encoder_length - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    max_encoder_length= max_encoder_length,\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Passengers\",\n",
    "    group_ids=[\"group\"],\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=['month'],\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_unknown_reals=[\"Passengers\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    target_normalizer=TorchNormalizer(method=\"standard\",\n",
    "                                      transformation=None),\n",
    "    )\n",
    "\n",
    "training.get_parameters()\n",
    "validation = TimeSeriesDataSet.from_dataset(training,\n",
    "                                            data[lambda x: x.time_idx > training_cutoff])\n",
    "\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(training, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "val_dataloader = DataLoader(validation, batch_size=batch_size, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method LightningModule.summarize of TCNModel(\n",
       "  (loss): MSELoss()\n",
       "  (logging_metrics): ModuleList()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (out_linear): Linear(in_features=18, out_features=12, bias=True)\n",
       "  (res_blocks): ModuleList(\n",
       "    (0): ResidualBlock(\n",
       "      (dropout_fn): Dropout(p=0.2, inplace=False)\n",
       "      (conv1): Conv1d(1, 16, kernel_size=(2,), stride=(1,))\n",
       "      (conv2): Conv1d(16, 16, kernel_size=(2,), stride=(1,))\n",
       "      (conv3): Conv1d(1, 16, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (dropout_fn): Dropout(p=0.2, inplace=False)\n",
       "      (conv1): Conv1d(16, 16, kernel_size=(2,), stride=(1,), dilation=(2,))\n",
       "      (conv2): Conv1d(16, 1, kernel_size=(2,), stride=(1,), dilation=(2,))\n",
       "      (conv3): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(123)\n",
    "# create PyTorch Lighning Trainer with early stopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4,\n",
    "                                    patience=60, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    gpus=0,  # run on CPU, if on multiple GPUs, use accelerator=\"ddp\"\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # 30 batches per epoch\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=TensorBoardLogger(\"lightning_logs\")\n",
    ")\n",
    "\n",
    "model = TCNModel.from_dataset(training,\n",
    "                              kernel_size=2,\n",
    "                              num_filters=16,\n",
    "                              num_layers=2,\n",
    "                              dilation_base=2,\n",
    "                              weight_norm=False,\n",
    "                              target_size=1,\n",
    "                              dropout=0.2,\n",
    "                              )\n",
    "                                      \n",
    "model.summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dilation_base\":       2\n",
       "\"dropout\":             0.2\n",
       "\"input_length\":        18\n",
       "\"kernel_size\":         2\n",
       "\"learning_rate\":       0.001\n",
       "\"log_interval\":        -1\n",
       "\"log_val_interval\":    None\n",
       "\"logging_metrics\":     ModuleList()\n",
       "\"loss\":                MSELoss()\n",
       "\"monotone_constaints\": {}\n",
       "\"num_filters\":         16\n",
       "\"num_layers\":          2\n",
       "\"output_transformer\":  TorchNormalizer()\n",
       "\"prediction_length\":   12\n",
       "\"reals\":               ['Passengers']\n",
       "\"target_size\":         1\n",
       "\"weight_norm\":         False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MSELoss    | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | dropout         | Dropout    | 0     \n",
      "3 | out_linear      | Linear     | 228   \n",
      "4 | res_blocks      | ModuleList | 1.2 K \n",
      "-----------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "D:\\Anaconda3\\envs\\DeepTS_Forecasting\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory lightning_logs\\default\\version_18\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[417.0000],\n",
      "         [391.0000],\n",
      "         [419.0000],\n",
      "         [461.0000],\n",
      "         [472.0000],\n",
      "         [535.0000],\n",
      "         [622.0000],\n",
      "         [606.0000],\n",
      "         [508.0000],\n",
      "         [461.0000],\n",
      "         [390.0000],\n",
      "         [432.0000]],\n",
      "\n",
      "        [[401.7584],\n",
      "         [402.7410],\n",
      "         [420.2169],\n",
      "         [433.6198],\n",
      "         [467.2556],\n",
      "         [554.4698],\n",
      "         [617.7528],\n",
      "         [647.0651],\n",
      "         [570.2883],\n",
      "         [484.3043],\n",
      "         [394.6578],\n",
      "         [391.2507]]], dtype=torch.float64)\n",
      "MAE is: tensor(21.3422, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader,\n",
    ")\n",
    "\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = TCNModel.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([model.transform_output(prediction=y, target_scale=x['target_scale'])\n",
    "                     for x, y in iter(val_dataloader)])\n",
    "predictions, x_index = best_model.predict(val_dataloader)\n",
    "mae = (actuals - predictions).abs().mean()\n",
    "# print('predictions shape is:', predictions.shape)\n",
    "# print('actuals shape is:', actuals.shape)\n",
    "print(torch.cat([actuals, predictions]))\n",
    "print('MAE is:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[237.7456,  88.2423]]], dtype=torch.float64) tensor([[[2.0314],\n",
      "         [1.7367],\n",
      "         [2.0541],\n",
      "         [2.5300],\n",
      "         [2.6547],\n",
      "         [3.3686],\n",
      "         [4.3545],\n",
      "         [4.1732],\n",
      "         [3.0626],\n",
      "         [2.5300],\n",
      "         [1.7254],\n",
      "         [2.2014]]])\n"
     ]
    }
   ],
   "source": [
    " for x, y in iter(val_dataloader):\n",
    "    print(x['target_scale'],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = torch.cat([model.transform_output(prediction=y, target_scale=x['target_scale'])\n",
    "                     for x, y in iter(val_dataloader)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[417.0000],\n",
       "         [391.0000],\n",
       "         [419.0000],\n",
       "         [461.0000],\n",
       "         [472.0000],\n",
       "         [535.0000],\n",
       "         [622.0000],\n",
       "         [606.0000],\n",
       "         [508.0000],\n",
       "         [461.0000],\n",
       "         [390.0000],\n",
       "         [432.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
