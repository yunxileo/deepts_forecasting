{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install deepts_forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from deepts_forecasting.utils.data import TimeSeriesDataSet\n",
    "from deepts_forecasting.utils.data.encoders import TorchNormalizer\n",
    "from deepts_forecasting.datasets import AirPassengersDataset\n",
    "from deepts_forecasting.models.transformer import TransformerModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>group</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02-01</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03-01</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04-01</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05-01</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  Passengers  year month group  time_idx\n",
       "0 1949-01-01       112.0  1949     1     0         0\n",
       "1 1949-02-01       118.0  1949     2     0         1\n",
       "2 1949-03-01       132.0  1949     3     0         2\n",
       "3 1949-04-01       129.0  1949     4     0         3\n",
       "4 1949-05-01       121.0  1949     5     0         4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = AirPassengersDataset().load()\n",
    "data['year'] = data['Month'].dt.year\n",
    "data['month'] = data['Month'].dt.month\n",
    "data['group'] = '0'\n",
    "data['time_idx'] = np.arange(len(data))\n",
    "data['Passengers'] = data['Passengers'].astype(float)\n",
    "data['month'] = data['month'].astype('str')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 18\n",
    "max_prediction_length = 12\n",
    "\n",
    "training_cutoff = data[\"time_idx\"].max() - max_encoder_length - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    max_encoder_length= max_encoder_length,\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Passengers\",\n",
    "    group_ids=[\"group\"],\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=['month'],\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_unknown_reals=[\"Passengers\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    target_normalizer=TorchNormalizer(method=\"standard\",\n",
    "                                      transformation=None),\n",
    "    )\n",
    "\n",
    "training.get_parameters()\n",
    "validation = TimeSeriesDataSet.from_dataset(training,\n",
    "                                            data[lambda x: x.time_idx > training_cutoff])\n",
    "\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(training, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "val_dataloader = DataLoader(validation, batch_size=batch_size, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method LightningModule.summarize of TransformerModel(\n",
       "  (loss): L1Loss()\n",
       "  (logging_metrics): ModuleList()\n",
       "  (encoder_input_linear): Linear(in_features=7, out_features=16, bias=True)\n",
       "  (decoder_input_linear): Linear(in_features=6, out_features=16, bias=True)\n",
       "  (encoder_positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder_positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (out_linear): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (embeddings): ModuleDict(\n",
       "    (month): Embedding(12, 6)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(123)\n",
    "# create PyTorch Lighning Trainer with early stopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4,\n",
    "                                    patience=60, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    gpus=0,  # run on CPU, if on multiple GPUs, use accelerator=\"ddp\"\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # 30 batches per epoch\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=TensorBoardLogger(\"lightning_logs\")\n",
    ")\n",
    "\n",
    "model = TransformerModel.from_dataset(training,\n",
    "                                      dim_feedforward=32,\n",
    "                                      n_head=1,\n",
    "                                      n_layers=2,\n",
    "                                      d_model=16,\n",
    "                                      )\n",
    "model.summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"activation\":                        relu\n",
       "\"categorical_groups\":                {}\n",
       "\"d_model\":                           16\n",
       "\"dim_feedforward\":                   32\n",
       "\"dropout\":                           0.1\n",
       "\"embedding_labels\":                  {'month': array(['1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       "      dtype=object)}\n",
       "\"embedding_paddings\":                []\n",
       "\"embedding_sizes\":                   {'month': [12, 6]}\n",
       "\"learning_rate\":                     0.001\n",
       "\"log_interval\":                      -1\n",
       "\"log_val_interval\":                  None\n",
       "\"logging_metrics\":                   ModuleList()\n",
       "\"loss\":                              L1Loss()\n",
       "\"max_encoder_length\":                18\n",
       "\"max_prediction_length\":             12\n",
       "\"monotone_constaints\":               {}\n",
       "\"n_head\":                            1\n",
       "\"n_layers\":                          2\n",
       "\"output_size\":                       1\n",
       "\"output_transformer\":                TorchNormalizer()\n",
       "\"static_categoricals\":               []\n",
       "\"static_reals\":                      []\n",
       "\"time_varying_categoricals_decoder\": ['month']\n",
       "\"time_varying_categoricals_encoder\": ['month']\n",
       "\"time_varying_reals_decoder\":        []\n",
       "\"time_varying_reals_encoder\":        ['Passengers']\n",
       "\"x_categoricals\":                    ['month']\n",
       "\"x_reals\":                           ['Passengers']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                        | Type               | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | loss                        | L1Loss             | 0     \n",
      "1 | logging_metrics             | ModuleList         | 0     \n",
      "2 | encoder_input_linear        | Linear             | 128   \n",
      "3 | decoder_input_linear        | Linear             | 112   \n",
      "4 | encoder_positional_encoding | PositionalEncoding | 0     \n",
      "5 | decoder_positional_encoding | PositionalEncoding | 0     \n",
      "6 | transformer_encoder         | TransformerEncoder | 4.5 K \n",
      "7 | transformer_decoder         | TransformerDecoder | 6.7 K \n",
      "8 | out_linear                  | Linear             | 17    \n",
      "9 | embeddings                  | ModuleDict         | 72    \n",
      "-------------------------------------------------------------------\n",
      "11.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n",
      "D:\\Anaconda3\\envs\\DeepTS_Forecasting\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory lightning_logs\\default\\version_17\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[417.0000],\n",
      "         [391.0000],\n",
      "         [419.0000],\n",
      "         [461.0000],\n",
      "         [472.0000],\n",
      "         [535.0000],\n",
      "         [622.0000],\n",
      "         [606.0000],\n",
      "         [508.0000],\n",
      "         [461.0000],\n",
      "         [390.0000],\n",
      "         [432.0000]],\n",
      "\n",
      "        [[350.6286],\n",
      "         [331.8389],\n",
      "         [368.7483],\n",
      "         [367.6466],\n",
      "         [376.8046],\n",
      "         [437.5001],\n",
      "         [456.6611],\n",
      "         [470.3661],\n",
      "         [442.6349],\n",
      "         [358.7311],\n",
      "         [334.2704],\n",
      "         [360.6251]]], dtype=torch.float64)\n",
      "MAE is: tensor(88.1287, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader,\n",
    ")\n",
    "\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = TransformerModel.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([model.transform_output(prediction=y, target_scale=x['target_scale'])\n",
    "                     for x, y in iter(val_dataloader)])\n",
    "predictions, x_index = best_model.predict(val_dataloader)\n",
    "mae = (actuals - predictions).abs().mean()\n",
    "# print('predictions shape is:', predictions.shape)\n",
    "# print('actuals shape is:', actuals.shape)\n",
    "print(torch.cat([actuals, predictions]))\n",
    "print('MAE is:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
